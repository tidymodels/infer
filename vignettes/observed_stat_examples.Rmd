---
title: "Full infer Pipeline Examples"
output: 
  rmarkdown::html_vignette:
    df_print: kable
    toc: true
vignette: |
  %\VignetteIndexEntry{Full infer pipeline examples}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

#### Introduction

```{r include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.height = 4.5) 
options(digits = 4)
```

This vignette is intended to provide a set of examples that nearly exhaustively demonstrate the functionalities provided by `infer`. Commentary on these examples is limited---for more discussion of the intuition behind the package, see the "Getting to Know infer" vignette, accessible by calling `vignette("infer")`.

Throughout this vignette, we'll make use of the `gss` dataset supplied by `infer`, which contains a sample of data from the General Social Survey. See `?gss` for more information on the variables included and their source. Note that this data (and our examples on it) are for demonstration purposes only, and will not necessarily provide accurate estimates unless weighted properly. For these examples, let's suppose that this dataset is a representative sample of a population we want to learn about: American adults. The data looks like this:

```{r load-packages, echo = FALSE, message = FALSE, warning = FALSE}
library(devtools)
library(dplyr)
library(tidyr)
devtools::load_all()
```


```{r load-gss, warning = FALSE, message = FALSE}
# load in the dataset
data(gss)

# take a look at its structure
dplyr::glimpse(gss)
```

## Hypothesis tests

### One numerical variable (mean)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
x_bar <- gss %>%
  specify(response = hours) %>%
  calculate(stat = "mean")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(response = hours) %>%
  hypothesize(null = "point", mu = 40) %>%
  generate(reps = 1000) %>%
  calculate(stat = "mean")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = x_bar, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = x_bar, direction = "two_sided")
```

### One numerical variable (standardized mean $t$)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
t_bar <- gss %>%
  specify(response = hours) %>%
  hypothesize(null = "point", mu = 40) %>%
  calculate(stat = "t")
```

Alternatively, using the wrapper to calculate the test statistic, 

```{r, message = FALSE, warning = FALSE}
t_bar <- gss %>%
  t_stat(response = hours, mu = 40)
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(response = hours) %>%
  hypothesize(null = "point", mu = 40) %>%
  generate(reps = 1000) %>%
  calculate(stat = "t")
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
  specify(response = hours) %>%
  hypothesize(null = "point", mu = 40) %>%
  calculate(stat = "t")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = t_bar, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = t_bar, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn, method = "both") +
  shade_p_value(obs_stat = t_bar, direction = "two_sided")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = t_bar, direction = "two_sided")
```

Alternatively, using the `t_test` wrapper:

```{r, message = FALSE, warning = FALSE}
gss %>%
  t_test(response = hours, mu = 40)
```


### One numerical variable (median)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
x_tilde <- gss %>%
  specify(response = age) %>%
  calculate(stat = "median")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(response = age) %>%
  hypothesize(null = "point", med = 40) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "median")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = x_tilde, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = x_tilde, direction = "two_sided")
```

### One categorical (one proportion)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
p_hat <- gss %>%
  specify(response = sex, success = "female") %>%
  calculate(stat = "prop")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(response = sex, success = "female") %>%
  hypothesize(null = "point", p = .5) %>%
  generate(reps = 1000) %>%
  calculate(stat = "prop")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = p_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = p_hat, direction = "two_sided")
```

Note that logical variables will be coerced to factors:

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  dplyr::mutate(is_female = (sex == "female")) %>%
  specify(response = is_female, success = "TRUE") %>%
  hypothesize(null = "point", p = .5) %>%
  generate(reps = 1000) %>%
  calculate(stat = "prop")
```

### One categorical variable (standardized proportion $z$)

Not yet implemented.

### Two categorical (2 level) variables

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
d_hat <- gss %>% 
  specify(college ~ sex, success = "no degree") %>%
  calculate(stat = "diff in props", order = c("female", "male"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(college ~ sex, success = "no degree") %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "diff in props", order = c("female", "male"))
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = d_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = d_hat, direction = "two_sided")
```

### Two categorical (2 level) variables (z)

Finding the standardized observed statistic,

```{r, message = FALSE, warning = FALSE}
z_hat <- gss %>% 
  specify(college ~ sex, success = "no degree") %>%
  calculate(stat = "z", order = c("female", "male"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(college ~ sex, success = "no degree") %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "z", order = c("female", "male"))
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
  specify(college ~ sex, success = "no degree") %>%
  hypothesize(null = "independence") %>%  
  calculate(stat = "z", order = c("female", "male"))
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = z_hat, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = z_hat, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn, method = "both") +
  shade_p_value(obs_stat = z_hat, direction = "two_sided")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = z_hat, direction = "two_sided")
```

Note the similarities in this plot and the previous one.

### One categorical (>2 level) - GoF

Calculating the observed statistic,

Note the need to add in the hypothesized values here to compute the observed statistic.

```{r, message = FALSE, warning = FALSE}
Chisq_hat <- gss %>%
  specify(response = finrela) %>%
  hypothesize(null = "point",
              p = c("far below average" = 1/6,
                    "below average" = 1/6,
                    "average" = 1/6,
                    "above average" = 1/6,
                    "far above average" = 1/6,
                    "DK" = 1/6)) %>%
  calculate(stat = "Chisq")
```

Alternatively, using the `chisq_stat` wrapper to calculate the test statistic,

```{r, message = FALSE, warning = FALSE}
Chisq_hat <- gss %>%
  chisq_stat(response = finrela,
             p = c("far below average" = 1/6,
                   "below average" = 1/6,
                   "average" = 1/6,
                   "above average" = 1/6,
                   "far above average" = 1/6,
                   "DK" = 1/6))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(response = finrela) %>%
  hypothesize(null = "point",
              p = c("far below average" = 1/6,
                    "below average" = 1/6,
                    "average" = 1/6,
                    "above average" = 1/6,
                    "far above average" = 1/6,
                    "DK" = 1/6)) %>%
  generate(reps = 1000, type = "simulate") %>%
  calculate(stat = "Chisq")
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
  specify(response = finrela) %>%
  hypothesize(null = "point",
              p = c("far below average" = 1/6,
                    "below average" = 1/6,
                    "average" = 1/6,
                    "above average" = 1/6,
                    "far above average" = 1/6,
                    "DK" = 1/6)) %>%
  calculate(stat = "Chisq")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "both") +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, using the `chisq_test` wrapper:

```{r, message = FALSE, warning = FALSE}
chisq_test(gss, 
           response = finrela,
           p = c("far below average" = 1/6,
                 "below average" = 1/6,
                 "average" = 1/6,
                 "above average" = 1/6,
                 "far above average" = 1/6,
                 "DK" = 1/6))
```

### Two categorical (>2 level): Chi-squared test of independence

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
Chisq_hat <- gss %>%
  specify(formula = partyid ~ class) %>% 
  calculate(stat = "Chisq")
```

Alternatively, using the wrapper to calculate the test statistic,

```{r, message = FALSE, warning = FALSE}
Chisq_hat <- gss %>%
  chisq_stat(formula = partyid ~ class)
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(partyid ~ class) %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "Chisq")
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
  specify(partyid ~ class) %>%
  hypothesize(null = "independence") %>% 
  calculate(stat = "Chisq")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn, method = "both") +
  shade_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = Chisq_hat, direction = "greater")
```

Alternatively, using the wrapper to carry out the test,

```{r, message = FALSE, warning = FALSE}
gss %>%
  chisq_test(formula = partyid ~ class)
```

### One numerical variable, one categorical (2 levels) (diff in means)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
d_hat <- gss %>% 
  specify(age ~ college) %>% 
  calculate(stat = "diff in means", order = c("degree", "no degree"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(age ~ college) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("degree", "no degree"))
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = d_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = d_hat, direction = "two_sided")
```

### One numerical variable, one categorical (2 levels) (t)

Finding the standardized observed statistic,

```{r, message = FALSE, warning = FALSE}
t_hat <- gss %>% 
  specify(age ~ college) %>% 
  calculate(stat = "t", order = c("degree", "no degree"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(age ~ college) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("degree", "no degree"))
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
  specify(age ~ college) %>%
  hypothesize(null = "independence") %>%
  calculate(stat = "t", order = c("degree", "no degree"))
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = t_hat, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = t_hat, direction = "two_sided")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn, method = "both") +
  shade_p_value(obs_stat = t_hat, direction = "two_sided")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = t_hat, direction = "two_sided")
```

Note the similarities in this plot and the previous one.

### One numerical variable, one categorical (2 levels) (diff in medians)

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
d_hat <- gss %>% 
  specify(age ~ college) %>% 
  calculate(stat = "diff in medians", order = c("degree", "no degree"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
  specify(age ~ college) %>% # alt: response = age, explanatory = season
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in medians", order = c("degree", "no degree"))
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = d_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = d_hat, direction = "two_sided")
```

### One numerical, one categorical (>2 levels) -  ANOVA

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
F_hat <- gss %>% 
  specify(age ~ partyid) %>%
  calculate(stat = "F")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
   specify(age ~ partyid) %>%
   hypothesize(null = "independence") %>%
   generate(reps = 1000, type = "permute") %>%
   calculate(stat = "F")
```

Alternatively, finding the null distribution using theoretical methods by skipping the `generate(reps = 1000)` step,

```{r, message = FALSE, warning = FALSE}
null_distn_theoretical <- gss %>%
   specify(age ~ partyid) %>%
   hypothesize(null = "independence") %>%
   calculate(stat = "F")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = F_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using the theory-based null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn_theoretical, method = "theoretical") +
  shade_p_value(obs_stat = F_hat, direction = "greater")
```

Alternatively, visualizing the observed statistic using both of the null distributions,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn, mdthod = "both") +
  shade_p_value(obs_stat = F_hat, direction = "greater")
```

Note that the above code makes use of the simulation-based null distribution.

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = F_hat, direction = "greater")
```

### Two numerical vars - SLR 

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
slope_hat <- gss %>% 
  specify(hours ~ age) %>% 
  calculate(stat = "slope")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
   specify(hours ~ age) %>% 
   hypothesize(null = "independence") %>%
   generate(reps = 1000, type = "permute") %>%
   calculate(stat = "slope")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = slope_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = slope_hat, direction = "two_sided")
```

### Two numerical vars - correlation

Calculating the observed statistic,

```{r, message = FALSE, warning = FALSE}
correlation_hat <- gss %>% 
  specify(hours ~ age) %>% 
  calculate(stat = "correlation")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
null_distn <- gss %>%
   specify(hours ~ age) %>% 
   hypothesize(null = "independence") %>%
   generate(reps = 1000, type = "permute") %>%
   calculate(stat = "correlation")
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(null_distn) +
  shade_p_value(obs_stat = correlation_hat, direction = "two_sided")
```

Calculating the p-value from the null distribution and observed statistic,

```{r, message = FALSE, warning = FALSE}
null_distn %>%
  get_p_value(obs_stat = correlation_hat, direction = "two_sided")
```


### Two numerical vars - SLR (t)

Not currently implemented since $t$ could refer to standardized slope or standardized correlation.

## Confidence intervals

### One numerical (one mean)

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
x_bar <- gss %>% 
  specify(response = hours) %>%
  calculate(stat = "mean")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(response = hours) %>%
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "mean")
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- get_ci(boot, type = "se", point_estimate = x_bar)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```

### One numerical (one mean - standardized)

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
t_hat <- gss %>% 
  specify(response = hours) %>%
  calculate(stat = "t")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(response = hours) %>%
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "t")
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = t_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```


### One categorical (one proportion)

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
p_hat <- gss %>% 
   specify(response = sex, success = "female") %>%
   calculate(stat = "prop")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
 specify(response = sex, success = "female") %>%
 generate(reps = 1000, type = "bootstrap") %>%
 calculate(stat = "prop")
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = p_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```

### One categorical variable (standardized proportion $z$)

Not yet implemented.

### One numerical variable, one categorical (2 levels) (diff in means)

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
d_hat <- gss %>%
  specify(hours ~ college) %>%
  calculate(stat = "diff in means", order = c("degree", "no degree"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(hours ~ college) %>%
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "diff in means", order = c("degree", "no degree"))
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = d_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```

### One numerical variable, one categorical (2 levels) (t)

Finding the standardized point estimate,

```{r, message = FALSE, warning = FALSE}
t_hat <- gss %>%
  specify(hours ~ college) %>%
  calculate(stat = "t", order = c("degree", "no degree"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(hours ~ college) %>%
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "t", order = c("degree", "no degree"))
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = t_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```


### Two categorical variables (diff in proportions)

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
d_hat <- gss %>% 
  specify(college ~ sex, success = "degree") %>%
  calculate(stat = "diff in props", order = c("female", "male"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
  specify(college ~ sex, success = "degree") %>%
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("female", "male"))
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = d_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```

### Two categorical variables (z)

Finding the standardized point estimate,

```{r, message = FALSE, warning = FALSE}
z_hat <- gss %>% 
  specify(college ~ sex, success = "degree") %>%
  calculate(stat = "z", order = c("female", "male"))
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
  specify(college ~ sex, success = "degree") %>%
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "z", order = c("female", "male"))
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = z_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```


### Two numerical vars - SLR

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
slope_hat <- gss %>% 
  specify(hours ~ age) %>%
  calculate(stat = "slope")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(hours ~ age) %>% 
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "slope")
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = slope_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```

### Two numerical vars - correlation

Finding the observed statistic,

```{r, message = FALSE, warning = FALSE}
correlation_hat <- gss %>% 
  specify(hours ~ age) %>%
  calculate(stat = "correlation")
```

Then, generating the null distribution,

```{r, message = FALSE, warning = FALSE}
boot <- gss %>%
   specify(hours ~ age) %>% 
   generate(reps = 1000, type = "bootstrap") %>%
   calculate(stat = "correlation")
```

Use the null distribution to find a confidence interval,

```{r, message = FALSE, warning = FALSE}
percentile_ci <- get_ci(boot)
```

Visualizing the observed statistic alongside the null distribution,

```{r, message = FALSE, warning = FALSE}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Alternatively, use the null distribution to find a confidence interval using the standard error,

```{r, message = FALSE, warning = FALSE}
standard_error_ci <- boot %>%
  get_ci(type = "se", point_estimate = correlation_hat)

visualize(boot) +
  shade_confidence_interval(endpoints = standard_error_ci)
```


### Two numerical vars - t

Not currently implemented since $t$ could refer to standardized slope or standardized correlation.
